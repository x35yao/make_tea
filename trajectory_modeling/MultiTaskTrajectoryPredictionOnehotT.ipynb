{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 20:04:10.309244: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-19 20:04:10.392366: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-19 20:04:10.393722: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-19 20:04:11.587844: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n",
      "Cuda available:  True\n",
      "The outliers for individual teabag1 are ['134734', '134772']\n",
      "The outliers for individual cup are ['134732', '134733', '134734', '134726', '134742', '134735']\n",
      "The number of training pool for task 2022-10-06 is: 30\n",
      "The number of outliers is: 7 with remaining 44\n",
      "Training/Test Size: 30/7/7\n",
      "The outliers for individual pitcher are ['331733']\n",
      "The outliers for individual cup are ['331733']\n",
      "The number of training pool for task 2022-10-27 is: 30\n",
      "The number of outliers is: 1 with remaining 46\n",
      "Training/Test Size: 30/8/8\n",
      "The outliers for individual net are ['882800', '882789', '882817', '882823', '882831']\n",
      "The outliers for individual puck are []\n",
      "The number of training pool for task 2022-12-01 is: 30\n",
      "The number of outliers is: 5 with remaining 40\n",
      "Training/Test Size: 30/5/5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from statistics import mean\n",
    "from plot import remove_repetitive_labels\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from transformer_model import *\n",
    "from process_data import Task_data\n",
    "from outlier_detection import detect_outlier\n",
    "from transformations import *\n",
    "\n",
    "def get_position_difference_per_step(d1, d2):\n",
    "    return np.linalg.norm(d1 - d2, axis = 1)\n",
    "\n",
    "\n",
    "def swap_dict_level(data):\n",
    "    temp = {}\n",
    "    for obj, value in data.items():\n",
    "        for demo, traj in value.items():\n",
    "            if not demo in temp:\n",
    "                temp[demo] = {}\n",
    "            temp[demo][obj] = traj\n",
    "    return temp\n",
    "\n",
    "def create_tags(objs):\n",
    "    one_hots = torch.eye(len(objs))\n",
    "    tag_dict = {}\n",
    "    for i, obj in enumerate(objs):\n",
    "        tag_dict[obj] = one_hots[i]\n",
    "    return tag_dict\n",
    "\n",
    "def random_rotation(x, axis='x'):\n",
    "    new_x = x.copy()\n",
    "    degree, idx = random.randrange(0, 360), random.randrange(0, x.shape[0])\n",
    "    rot = R.from_euler(axis, degree, degrees=True)\n",
    "    H = np.zeros([4,4])\n",
    "    H[:3,:3] = rot.as_matrix()\n",
    "    rand_pt = x[idx,:3].copy()\n",
    "#     rand_pt[1:] = rand_pt[1:]\n",
    "#     print(\"pre:\",new_x)\n",
    "    new_x[:,:3]  = new_x[:,:3] - rand_pt\n",
    "    new_x = lintrans(new_x, H)\n",
    "    new_x[:,:3] = new_x[:,:3] + rand_pt\n",
    "#     print(\"post:\",new_x)\n",
    "    return new_x\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Cuda available: \", torch.cuda.is_available())\n",
    "seed = 321\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "colors = ['red', 'blue', 'yellow', 'orange', 'green', 'purple','pink']\n",
    "task_files = [\"2022-10-06\", \"2022-10-27\", \"2022-12-01\"]\n",
    "data_dir = '../Process_data/postprocessed'\n",
    "# task_dims = ['x', 'y', 'z']\n",
    "task_dims = ['x', 'y', 'z', 'qx', 'qy', 'qz', 'qw']\n",
    "n_dims = len(task_dims)\n",
    "n_train = 30\n",
    "n_tasks = len(task_files)\n",
    "\n",
    "\n",
    "# find all objects first\n",
    "all_objs = []\n",
    "for file in task_files:\n",
    "    task_config_dir = os.path.join(data_dir, file)\n",
    "    with open(os.path.join(task_config_dir, 'task_config.yaml')) as file:\n",
    "        config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    objs = config[\"individuals\"]\n",
    "    all_objs = all_objs + objs\n",
    "unique_objs = ['trajectory'] + sorted(list(set(all_objs)))\n",
    "n_objs = len(unique_objs)\n",
    "\n",
    "obj_tags = create_tags(unique_objs)\n",
    "task_tags = create_tags(task_files)\n",
    "\n",
    "train_objs_pos, train_traj_pos = [], []\n",
    "valid_objs_pos, valid_traj_pos = [], []\n",
    "test_objs_pos, test_traj_pos = [], []\n",
    "\n",
    "# Load data\n",
    "for task_file in task_files:\n",
    "    task_config_dir = os.path.join(data_dir, task_file)\n",
    "    with open(os.path.join(task_config_dir, 'task_config.yaml')) as file:\n",
    "        config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    project_dir = config[\"project_path\"] # Modify this to your need\n",
    "    base_dir = os.path.join(project_dir, config[\"postprocessed_dir\"])\n",
    "    triangulation = 'dlc3d'\n",
    "    template_dir = os.path.join(project_dir, config[\"postprocessed_dir\"],f'transformations/{triangulation}')\n",
    "    individuals = config[\"individuals\"] # The objects that we will place a reference frame on\n",
    "\n",
    "    with open(os.path.join(base_dir, 'processed', triangulation, 'gripper_trajs_in_obj_aligned_filtered.pickle',), 'rb') as f1:\n",
    "        gripper_trajs_in_obj_all_actions = pickle.load(f1)\n",
    "    with open(os.path.join(base_dir, 'processed', triangulation, 'HTs_obj_in_ndi.pickle',), 'rb') as f2:\n",
    "        HTs_obj_in_ndi_all_actions = pickle.load(f2)\n",
    "    with open(os.path.join(base_dir, 'processed', triangulation, 'gripper_traj_in_grouped_objs_aligned_filtered.pickle',), 'rb') as f3:\n",
    "        gripper_trajs_in_grouped_objs_all_actions = pickle.load(f3)\n",
    "    with open(os.path.join(base_dir, 'processed', triangulation, 'HTs_grouped_objs_in_ndi.pickle',), 'rb') as f4:\n",
    "        HTs_grouped_objs_in_ndi_all_actions = pickle.load(f4)\n",
    "\n",
    "    ind = 0  # index of action to be tested\n",
    "    # gripper_trajs_in_ndi = gripper_trajs_truncated[ind]\n",
    "    gripper_traj_in_obj = gripper_trajs_in_obj_all_actions[ind]\n",
    "    gripper_traj_in_grouped_obj = gripper_trajs_in_grouped_objs_all_actions[ind]\n",
    "    gripper_traj_in_generalized_obj = gripper_traj_in_obj | gripper_traj_in_grouped_obj\n",
    "\n",
    "    HTs_obj_in_ndi = HTs_obj_in_ndi_all_actions[ind]\n",
    "    HTs_grouped_obj_in_ndi = HTs_grouped_objs_in_ndi_all_actions[ind]\n",
    "    if not 'global' in HTs_obj_in_ndi.keys():\n",
    "        HTs_obj_in_ndi = swap_dict_level(HTs_obj_in_ndi)\n",
    "        HTs_grouped_obj_in_ndi = swap_dict_level(HTs_grouped_obj_in_ndi)\n",
    "    HTs_generalized_obj_in_ndi = HTs_obj_in_ndi | HTs_grouped_obj_in_ndi\n",
    "\n",
    "    outliers = []\n",
    "    std_thres = 3\n",
    "\n",
    "    for individual in individuals:\n",
    "        n_std = std_thres\n",
    "        outlier_individual = detect_outlier(gripper_traj_in_generalized_obj[individual], n=n_std)\n",
    "        print(f'The outliers for individual {individual} are {outlier_individual}')\n",
    "        outliers += outlier_individual\n",
    "    outliers = list(set(outliers))\n",
    "    bad_demos = outliers\n",
    "\n",
    "    demos = sorted(list(HTs_generalized_obj_in_ndi['global'].keys()))\n",
    "    demos = [demo for demo in demos if demo not in bad_demos]\n",
    "    \n",
    "    train_demos_pool = [demo for demo in random.sample(demos,30)]\n",
    "    random.shuffle(train_demos_pool)\n",
    "    test_valid_demos_pool = [demo for demo in demos if demo not in train_demos_pool]\n",
    "    \n",
    "    train_demos = train_demos_pool[:n_train]\n",
    "    # validation and test demo split\n",
    "    test_valid_demos_pool_updated = [demo for demo in test_valid_demos_pool if demo not in train_demos]\n",
    "    split_size = int(len(test_valid_demos_pool_updated)/2)\n",
    "    valid_demos = test_valid_demos_pool_updated[:split_size]\n",
    "    test_demos = test_valid_demos_pool_updated[split_size:]\n",
    "    \n",
    "    print(f'The number of training pool for task {task_file} is: {len(train_demos_pool)}')\n",
    "    print(f'The number of outliers is: {len(outliers)} with remaining {len(demos)}')\n",
    "    print(f'Training/Test Size: {len(train_demos)}/{len(valid_demos)}/{len(test_demos)}')\n",
    "    for demo in train_demos:\n",
    "        traj = gripper_traj_in_obj['global'][demo][task_dims].to_numpy()\n",
    "        obj_buffer = obj_tags['trajectory'].repeat([traj.shape[0], 1])\n",
    "        task_buffer = task_tags[task_file].repeat([traj.shape[0], 1])\n",
    "        \n",
    "        new_traj_data = np.concatenate([traj, obj_buffer, task_buffer], axis=1)\n",
    "        obj_pos_all = [] \n",
    "        for obj_ind in individuals:\n",
    "            mat = HTs_generalized_obj_in_ndi[obj_ind][demo]\n",
    "            if n_dims==3:\n",
    "                obj_pos = np.concatenate([mat[:3,3], obj_tags[obj_ind], task_tags[task_file]])\n",
    "            else:\n",
    "                obj_pos = np.concatenate([mat[:3,3], R.from_matrix(mat[:3,:3]).as_quat(), obj_tags[obj_ind], task_tags[task_file]])\n",
    "            obj_pos_all.append(obj_pos)\n",
    "\n",
    "        train_objs_pos.append(np.stack(obj_pos_all))\n",
    "        train_traj_pos.append(new_traj_data)\n",
    "    \n",
    "    for demo in valid_demos:\n",
    "        traj = gripper_traj_in_obj['global'][demo][task_dims].to_numpy()\n",
    "        obj_buffer = obj_tags['trajectory'].repeat([traj.shape[0], 1])\n",
    "        task_buffer = task_tags[task_file].repeat([traj.shape[0], 1])\n",
    "        new_traj_data = np.concatenate([traj, obj_buffer, task_buffer], axis=1)\n",
    "        obj_pos_all = [] \n",
    "        for obj_ind in individuals:\n",
    "            mat = HTs_generalized_obj_in_ndi[obj_ind][demo]\n",
    "            if n_dims==3:\n",
    "                obj_pos = np.concatenate([mat[:3,3], obj_tags[obj_ind], task_tags[task_file]])\n",
    "            else:\n",
    "                obj_pos = np.concatenate([mat[:3,3], R.from_matrix(mat[:3,:3]).as_quat(), obj_tags[obj_ind], task_tags[task_file]])\n",
    "            obj_pos_all.append(obj_pos)\n",
    "\n",
    "        valid_objs_pos.append(np.stack(obj_pos_all))\n",
    "        valid_traj_pos.append(new_traj_data)\n",
    "    \n",
    "    for demo in test_demos:\n",
    "        traj = gripper_traj_in_obj['global'][demo][task_dims].to_numpy()\n",
    "        obj_buffer = obj_tags['trajectory'].repeat([traj.shape[0], 1])\n",
    "        task_buffer = task_tags[task_file].repeat([traj.shape[0], 1])\n",
    "        new_traj_data = np.concatenate([traj, obj_buffer, task_buffer], axis=1)\n",
    "        obj_pos_all = [] \n",
    "        for obj_ind in individuals:\n",
    "            mat = HTs_generalized_obj_in_ndi[obj_ind][demo]\n",
    "            if n_dims==3:\n",
    "                obj_pos = np.concatenate([mat[:3,3], obj_tags[obj_ind], task_tags[task_file]])\n",
    "            else:\n",
    "                obj_pos = np.concatenate([mat[:3,3], R.from_matrix(mat[:3,:3]).as_quat(), obj_tags[obj_ind], task_tags[task_file]])\n",
    "            obj_pos_all.append(obj_pos)\n",
    "\n",
    "        test_objs_pos.append(np.stack(obj_pos_all))\n",
    "        test_traj_pos.append(new_traj_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "contiguous_traj = np.concatenate(train_traj_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib.rcParams.update({'font.size': 10})\n",
    "# fig = plt.figure(figsize = (8, 6))\n",
    "# ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "# ax.set_facecolor('white')\n",
    "# ax.locator_params(nbins=3, axis='z')\n",
    "# colors = ['red', 'blue', 'yellow', 'orange', 'green', 'purple','pink']\n",
    "\n",
    "# ax.plot(contiguous_traj[:,2], contiguous_traj[:,1], -contiguous_traj[:,0], 'o')\n",
    "    \n",
    "# ax.set_xlabel('x (mm)')\n",
    "# ax.set_ylabel('y (mm)')\n",
    "# ax.set_zlabel('z (mm)')\n",
    "# ax.set_box_aspect([ub - lb for lb, ub in (getattr(ax, f'get_{a}lim')() for a in 'xyz')])\n",
    "# handles, labels = ax.get_legend_handles_labels()\n",
    "# newHandles_temp, newLabels_temp = remove_repetitive_labels(handles, labels)\n",
    "# newLabels, newHandles = [], []\n",
    "\n",
    "# for handle, label in zip(newHandles_temp, newLabels_temp):\n",
    "#     if label not in ['start', 'middle', 'end']:\n",
    "#         newLabels.append(label)\n",
    "#         newHandles.append(handle)\n",
    "# plt.legend(newHandles, newLabels, loc = 'upper left',  prop={'size': 10})\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, obj_data, traj_data, transform_dims, transform=lambda a : a,\n",
    "                 max_seq_len=128):\n",
    "        self.traj_data = traj_data\n",
    "        self.obj_data = obj_data\n",
    "        self.transform = transform\n",
    "        self.dims = transform_dims\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        traj_data = self.traj_data[idx].copy()\n",
    "        obj_data = self.obj_data[idx].copy()\n",
    "        x = np.concatenate([obj_data, traj_data])\n",
    "        # Transformation process\n",
    "        x[:,:self.dims] = self.transform(x[:,:self.dims])\n",
    "        \n",
    "        obj_data = torch.tensor(x[:obj_data.shape[0],:])\n",
    "        traj_data = torch.tensor(x[obj_data.shape[0]:,:])\n",
    "        if traj_data.shape[0] < self.max_seq_len:\n",
    "            diff = self.max_seq_len - traj_data.shape[0]\n",
    "            pad = torch.zeros([diff, traj_data.shape[1]])\n",
    "            traj_data = torch.cat([traj_data, pad])\n",
    "        traj_hidden = traj_data.clone()\n",
    "        traj_hidden[:,:self.dims] = 0\n",
    "        return obj_data, traj_data, traj_hidden\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.obj_data)\n",
    "\n",
    "def normalize_wrapper(average, std):\n",
    "    return lambda x: normalize_3d(x, average, std)\n",
    "\n",
    "def normalize_3d(entry, average, std):\n",
    "    entry[:,:3] = (entry[:,:3] - average)/std\n",
    "    return entry\n",
    "    \n",
    "def get_obj_tag(entry):\n",
    "    tag_seq = entry[n_dims:n_dims+n_objs]\n",
    "    return (tag_seq == 1).nonzero(as_tuple=True)[0]\n",
    "\n",
    "train_mean = np.mean(contiguous_traj[:,:3], axis=0)\n",
    "train_std = np.std(contiguous_traj[:,:3])/3\n",
    "\n",
    "norm_func = normalize_wrapper(train_mean, train_std)\n",
    "train_objs_pos = list(map(norm_func, train_objs_pos))\n",
    "train_traj_pos = list(map(norm_func, train_traj_pos))\n",
    "valid_objs_pos = list(map(norm_func, valid_objs_pos))\n",
    "valid_traj_pos = list(map(norm_func, valid_traj_pos))\n",
    "test_objs_pos = list(map(norm_func, test_objs_pos))\n",
    "test_traj_pos = list(map(norm_func, test_traj_pos))\n",
    "\n",
    "size_modifier = int(60/n_train)\n",
    "# Create dataloaders\n",
    "training_data = TrajectoryDataset(train_objs_pos*size_modifier, train_traj_pos*size_modifier,\n",
    "                                  n_dims, transform=random_rotation)\n",
    "valid_data = TrajectoryDataset(valid_objs_pos, valid_traj_pos, n_dims)\n",
    "test_data = TrajectoryDataset(test_objs_pos, test_traj_pos, n_dims)\n",
    "train_dataloader = DataLoader(training_data, batch_size=128, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=128, shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "# # shows random set of augmented trajectory\n",
    "# matplotlib.rcParams.update({'font.size': 10})\n",
    "# fig = plt.figure(figsize = (8, 6))\n",
    "# ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "# ax.set_facecolor('white')\n",
    "# ax.locator_params(nbins=3, axis='z')\n",
    "# colors = ['red', 'blue', 'yellow', 'orange', 'green', 'purple','pink']\n",
    "# for i_data, sample_data in enumerate(test_data):\n",
    "#     obj_seq, traj_seq, _ = sample_data\n",
    "#     traj_seq = traj_seq[traj_seq[:,n_dims]==1]\n",
    "#     if i_data%10: continue\n",
    "#     obj1_pos = obj_seq[1,]\n",
    "#     obj0_pos = obj_seq[0,]\n",
    "#     line = ax.plot(traj_seq[:,2], traj_seq[:,1], -traj_seq[:,0], '--', color=colors[i_data%len(colors)], \n",
    "#                    label = f'demo {i_data}')\n",
    "#     ax.plot(obj1_pos[2], obj1_pos[1], -obj1_pos[0], 'o',\n",
    "#             color=colors[i_data%len(colors)], label=f'{i_data}')\n",
    "#     ax.plot(obj0_pos[2], obj0_pos[1], -obj0_pos[0], 'x',\n",
    "#             color=colors[i_data%len(colors)], label=f'{i_data}')\n",
    "# ax.set_xlabel('x (mm)')\n",
    "# ax.set_ylabel('y (mm)')\n",
    "# ax.set_zlabel('z (mm)')\n",
    "# ax.set_box_aspect([ub - lb for lb, ub in (getattr(ax, f'get_{a}lim')() for a in 'xyz')])\n",
    "# handles, labels = ax.get_legend_handles_labels()\n",
    "# newHandles_temp, newLabels_temp = remove_repetitive_labels(handles, labels)\n",
    "# newLabels, newHandles = [], []\n",
    "\n",
    "# for handle, label in zip(newHandles_temp, newLabels_temp):\n",
    "#     if label not in ['start', 'middle', 'end']:\n",
    "#         newLabels.append(label)\n",
    "#         newHandles.append(handle)\n",
    "# plt.legend(newHandles, newLabels, loc = 'upper left',  prop={'size': 10})\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # shows random set of augmented trajectory\n",
    "# matplotlib.rcParams.update({'font.size': 10})\n",
    "# fig = plt.figure(figsize = (8, 6))\n",
    "# ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "# ax.set_facecolor('white')\n",
    "# ax.locator_params(nbins=3, axis='z')\n",
    "# colors = ['red', 'blue', 'yellow', 'orange', 'green', 'purple','pink']\n",
    "# for i_data, sample_data in enumerate(training_data):\n",
    "#     obj_seq, traj_seq, _ = sample_data\n",
    "#     traj_seq = traj_seq[traj_seq[:,n_dims]==1]\n",
    "#     if i_data%100: continue\n",
    "#     obj1_pos = obj_seq[1,]\n",
    "#     obj0_pos = obj_seq[0,]\n",
    "#     line = ax.plot(traj_seq[:,2], traj_seq[:,1], -traj_seq[:,0], '--', color=colors[i_data%len(colors)], \n",
    "#                    label = f'demo {i_data}')\n",
    "#     ax.plot(obj1_pos[2], obj1_pos[1], -obj1_pos[0], 'o',\n",
    "#             color=colors[i_data%len(colors)], label=f'{i_data}')\n",
    "#     ax.plot(obj0_pos[2], obj0_pos[1], -obj0_pos[0], 'x',\n",
    "#             color=colors[i_data%len(colors)], label=f'{i_data}')\n",
    "# ax.set_xlabel('x (mm)')\n",
    "# ax.set_ylabel('y (mm)')\n",
    "# ax.set_zlabel('z (mm)')\n",
    "# ax.set_box_aspect([ub - lb for lb, ub in (getattr(ax, f'get_{a}lim')() for a in 'xyz')])\n",
    "# handles, labels = ax.get_legend_handles_labels()\n",
    "# newHandles_temp, newLabels_temp = remove_repetitive_labels(handles, labels)\n",
    "# newLabels, newHandles = [], []\n",
    "\n",
    "# for handle, label in zip(newHandles_temp, newLabels_temp):\n",
    "#     if label not in ['start', 'middle', 'end']:\n",
    "#         newLabels.append(label)\n",
    "#         newHandles.append(handle)\n",
    "# plt.legend(newHandles, newLabels, loc = 'upper left',  prop={'size': 10})\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def loss_func(pred, truth):\n",
    "    losses = 0\n",
    "    for i in range(truth.shape[0]):\n",
    "        mask = truth[i,:,n_dims]==1\n",
    "        losses += F.mse_loss(pred[i,mask,:], truth[i,mask,:])\n",
    "    return losses/truth.shape[0]\n",
    "\n",
    "def train_epoch(model, optimizer, t_dataloader):\n",
    "    train_losses = []\n",
    "    model.train()\n",
    "    for sample_batched in t_dataloader:\n",
    "        # input modification\n",
    "        optimizer.zero_grad()\n",
    "        obj_seq, traj_seq, traj_target = sample_batched\n",
    "        obj_seq_input = obj_seq.to(device)\n",
    "        traj_seq_gt = traj_seq.to(device)\n",
    "        traj_target_input = traj_target.to(device)\n",
    "        output_seq = model(obj_seq_input, traj_target_input)\n",
    "        loss = F.mse_loss(output_seq, traj_seq_gt[:,:,:n_dims])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "    return train_losses\n",
    "        \n",
    "model_path = \"./models\"\n",
    "train_log_dir = './logs'\n",
    "checkpoint_file = os.path.join(model_path, f\"checkpoint2_{n_dims}D_{n_train}dms.pt\")\n",
    "# model_file = os.path.join(model_path, f\"saved_model_full_{n_dims}d_{n_train}demos.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_interval = 10\n",
    "best_score = 10000\n",
    "total_epochs = 50000\n",
    "loss_hist = []\n",
    "epoch = 0\n",
    "# Load model or create new\n",
    "# if os.path.exists(checkpoint_file):\n",
    "#     saved_file = torch.load(checkpoint_file)\n",
    "# #     best_score = saved_file['best_score']\n",
    "#     loss_hist = saved_file['losses']\n",
    "#     epoch = len(loss_hist)*print_interval\n",
    "#     new_model = saved_file['model']\n",
    "#     adam = saved_file['optimizer']\n",
    "#     print(\"Loaded Saved Model:\", checkpoint_file)\n",
    "# else:\n",
    "#     new_model = TFModelLite(task_dim=n_dims + n_objs + n_tasks, traj_dim=n_dims, \n",
    "#                             embed_dim=32, nhead=8, layers=3).to(device)\n",
    "#     adam = optim.Adam(new_model.parameters(), lr=1e-3)\n",
    "#     print(\"Create New Model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_arr = np.array(loss_hist)\n",
    "# fig = plt.figure(figsize = (8, 6))\n",
    "# plt.plot(loss_arr[:2500,0], label='training')\n",
    "# plt.plot(loss_arr[:2500,1], label='validation')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('per 10 epoch')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-19 20:04:18,808]\u001b[0m A new study created in memory with name: no-name-2604d1f5-f31d-4885-b331-979991e0d5c7\u001b[0m\n",
      "\u001b[32m[I 2023-04-19 20:13:03,067]\u001b[0m Trial 0 finished with value: 0.13931016186403627 and parameters: {'num_layers': 3, 'embed_size': 64, 'num_heads': 2, 'learning_rate': 0.0008344110015038636, 'dropout_rate': 0.6000000000000001}. Best is trial 0 with value: 0.13931016186403627.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1621/0.1393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-19 20:31:52,613]\u001b[0m Trial 1 finished with value: 0.4337856760693801 and parameters: {'num_layers': 2, 'embed_size': 256, 'num_heads': 2, 'learning_rate': 7.111748948798166e-05, 'dropout_rate': 0.8}. Best is trial 0 with value: 0.13931016186403627.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.2553/0.4338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-19 21:22:55,978]\u001b[0m Trial 2 finished with value: 0.13470240202944517 and parameters: {'num_layers': 6, 'embed_size': 256, 'num_heads': 4, 'learning_rate': 3.419743116598501e-05, 'dropout_rate': 0.4}. Best is trial 2 with value: 0.13470240202944517.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.3426/0.1347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-19 21:28:32,994]\u001b[0m Trial 3 finished with value: 0.10990427604199905 and parameters: {'num_layers': 1, 'embed_size': 32, 'num_heads': 16, 'learning_rate': 1.4603617084838966e-05, 'dropout_rate': 0.1}. Best is trial 3 with value: 0.10990427604199905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1136/0.1099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-19 21:34:09,578]\u001b[0m Trial 4 finished with value: 0.11617716170139747 and parameters: {'num_layers': 1, 'embed_size': 32, 'num_heads': 16, 'learning_rate': 4.2141211263364274e-05, 'dropout_rate': 0.30000000000000004}. Best is trial 3 with value: 0.10990427604199905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1472/0.1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-19 21:42:43,649]\u001b[0m Trial 5 finished with value: 0.11305385258101008 and parameters: {'num_layers': 4, 'embed_size': 16, 'num_heads': 1, 'learning_rate': 0.0023086968919588725, 'dropout_rate': 0.5}. Best is trial 3 with value: 0.10990427604199905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1439/0.1131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-19 21:56:48,437]\u001b[0m Trial 6 finished with value: 0.2672126004016175 and parameters: {'num_layers': 3, 'embed_size': 128, 'num_heads': 2, 'learning_rate': 0.0013745385019749367, 'dropout_rate': 0.6000000000000001}. Best is trial 3 with value: 0.10990427604199905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1958/0.2672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-19 22:07:36,551]\u001b[0m Trial 7 finished with value: 0.45044133161480354 and parameters: {'num_layers': 1, 'embed_size': 256, 'num_heads': 2, 'learning_rate': 0.0003164055983359737, 'dropout_rate': 0.0}. Best is trial 3 with value: 0.10990427604199905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.4314/0.4504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-19 22:19:43,893]\u001b[0m Trial 8 finished with value: 0.11201041530365023 and parameters: {'num_layers': 6, 'embed_size': 16, 'num_heads': 2, 'learning_rate': 2.7402237045114592e-05, 'dropout_rate': 0.4}. Best is trial 3 with value: 0.10990427604199905.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1479/0.112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-19 22:28:14,299]\u001b[0m Trial 9 finished with value: 0.10971861988648891 and parameters: {'num_layers': 3, 'embed_size': 64, 'num_heads': 1, 'learning_rate': 0.001749903175706015, 'dropout_rate': 0.8}. Best is trial 9 with value: 0.10971861988648891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1804/0.1097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-19 22:38:36,933]\u001b[0m Trial 10 finished with value: 0.14548981190790253 and parameters: {'num_layers': 4, 'embed_size': 64, 'num_heads': 1, 'learning_rate': 0.008925691530808242, 'dropout_rate': 1.0}. Best is trial 9 with value: 0.10971861988648891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.2131/0.1455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-19 22:47:06,330]\u001b[0m Trial 11 finished with value: 0.4237384890909454 and parameters: {'num_layers': 2, 'embed_size': 32, 'num_heads': 16, 'learning_rate': 1.11585847949996e-05, 'dropout_rate': 0.0}. Best is trial 9 with value: 0.10971861988648891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.4888/0.4237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-19 22:54:49,250]\u001b[0m Trial 12 finished with value: 0.11446869006047769 and parameters: {'num_layers': 2, 'embed_size': 64, 'num_heads': 8, 'learning_rate': 0.0001579032792179632, 'dropout_rate': 0.2}. Best is trial 9 with value: 0.10971861988648891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1371/0.1145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-19 23:12:15,353]\u001b[0m Trial 13 finished with value: 0.11928544603481853 and parameters: {'num_layers': 5, 'embed_size': 32, 'num_heads': 16, 'learning_rate': 1.1378739484441627e-05, 'dropout_rate': 0.8}. Best is trial 9 with value: 0.10971861988648891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1441/0.1193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-19 23:18:45,270]\u001b[0m Trial 14 finished with value: 0.17040495162813274 and parameters: {'num_layers': 1, 'embed_size': 128, 'num_heads': 1, 'learning_rate': 0.00030984207497204935, 'dropout_rate': 1.0}. Best is trial 9 with value: 0.10971861988648891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.2037/0.1704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-19 23:27:56,966]\u001b[0m Trial 15 finished with value: 0.2111507769157629 and parameters: {'num_layers': 3, 'embed_size': 64, 'num_heads': 4, 'learning_rate': 0.00013500511615935625, 'dropout_rate': 0.8}. Best is trial 9 with value: 0.10971861988648891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.229/0.2112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-19 23:41:49,677]\u001b[0m Trial 16 finished with value: 0.1144405054497664 and parameters: {'num_layers': 5, 'embed_size': 32, 'num_heads': 8, 'learning_rate': 0.004115476087067434, 'dropout_rate': 0.2}. Best is trial 9 with value: 0.10971861988648891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.141/0.1144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-19 23:50:23,098]\u001b[0m Trial 17 finished with value: 0.12055891485524996 and parameters: {'num_layers': 2, 'embed_size': 32, 'num_heads': 16, 'learning_rate': 0.0005738566919028195, 'dropout_rate': 0.7000000000000001}. Best is trial 9 with value: 0.10971861988648891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1559/0.1206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 00:00:42,620]\u001b[0m Trial 18 finished with value: 0.1116975330833974 and parameters: {'num_layers': 4, 'embed_size': 64, 'num_heads': 1, 'learning_rate': 0.0019690240814875457, 'dropout_rate': 0.1}. Best is trial 9 with value: 0.10971861988648891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1384/0.1117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 00:04:53,832]\u001b[0m Trial 19 finished with value: 0.12003800921834881 and parameters: {'num_layers': 1, 'embed_size': 16, 'num_heads': 1, 'learning_rate': 0.0007869495806299928, 'dropout_rate': 0.9}. Best is trial 9 with value: 0.10971861988648891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1457/0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 00:32:07,944]\u001b[0m Trial 20 finished with value: 0.11655530658732326 and parameters: {'num_layers': 5, 'embed_size': 128, 'num_heads': 16, 'learning_rate': 9.59942812367851e-05, 'dropout_rate': 0.6000000000000001}. Best is trial 9 with value: 0.10971861988648891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1542/0.1166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 00:42:30,814]\u001b[0m Trial 21 finished with value: 0.11136623013321938 and parameters: {'num_layers': 4, 'embed_size': 64, 'num_heads': 1, 'learning_rate': 0.0025843456766644316, 'dropout_rate': 0.1}. Best is trial 9 with value: 0.10971861988648891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1498/0.1114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 00:50:58,544]\u001b[0m Trial 22 finished with value: 0.1109778398055522 and parameters: {'num_layers': 3, 'embed_size': 64, 'num_heads': 1, 'learning_rate': 0.004005691077137172, 'dropout_rate': 0.1}. Best is trial 9 with value: 0.10971861988648891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1312/0.111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 00:59:25,788]\u001b[0m Trial 23 finished with value: 0.11084479056964658 and parameters: {'num_layers': 3, 'embed_size': 64, 'num_heads': 1, 'learning_rate': 0.00387417885069775, 'dropout_rate': 0.2}. Best is trial 9 with value: 0.10971861988648891.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1376/0.1108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 01:05:56,308]\u001b[0m Trial 24 finished with value: 0.1094187590337022 and parameters: {'num_layers': 2, 'embed_size': 64, 'num_heads': 1, 'learning_rate': 0.007880792589997262, 'dropout_rate': 0.30000000000000004}. Best is trial 24 with value: 0.1094187590337022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1427/0.1094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 01:12:26,983]\u001b[0m Trial 25 finished with value: 0.1176460273129138 and parameters: {'num_layers': 2, 'embed_size': 32, 'num_heads': 4, 'learning_rate': 0.00846606102359514, 'dropout_rate': 0.30000000000000004}. Best is trial 24 with value: 0.1094187590337022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1457/0.1176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 01:20:08,049]\u001b[0m Trial 26 finished with value: 0.11142625733566948 and parameters: {'num_layers': 2, 'embed_size': 64, 'num_heads': 8, 'learning_rate': 0.009961455762611898, 'dropout_rate': 0.30000000000000004}. Best is trial 24 with value: 0.1094187590337022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1486/0.1114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 01:25:58,773]\u001b[0m Trial 27 finished with value: 0.14193958097568485 and parameters: {'num_layers': 1, 'embed_size': 64, 'num_heads': 16, 'learning_rate': 0.0013481186949240388, 'dropout_rate': 0.4}. Best is trial 24 with value: 0.1094187590337022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1514/0.1419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 01:31:58,035]\u001b[0m Trial 28 finished with value: 0.11219276425454458 and parameters: {'num_layers': 2, 'embed_size': 32, 'num_heads': 1, 'learning_rate': 0.004938948994412617, 'dropout_rate': 0.5}. Best is trial 24 with value: 0.1094187590337022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1483/0.1122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 01:36:34,665]\u001b[0m Trial 29 finished with value: 0.1773780185575182 and parameters: {'num_layers': 1, 'embed_size': 64, 'num_heads': 1, 'learning_rate': 0.0010693367916944255, 'dropout_rate': 0.6000000000000001}. Best is trial 24 with value: 0.1094187590337022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1807/0.1774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 01:53:52,287]\u001b[0m Trial 30 finished with value: 0.4752698676707514 and parameters: {'num_layers': 3, 'embed_size': 128, 'num_heads': 16, 'learning_rate': 0.0004646815559176733, 'dropout_rate': 0.0}. Best is trial 24 with value: 0.1094187590337022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.416/0.4753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 02:02:21,587]\u001b[0m Trial 31 finished with value: 0.11321444845234613 and parameters: {'num_layers': 3, 'embed_size': 64, 'num_heads': 1, 'learning_rate': 0.006265682760154372, 'dropout_rate': 0.2}. Best is trial 24 with value: 0.1094187590337022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1352/0.1132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 02:10:51,063]\u001b[0m Trial 32 finished with value: 0.11848092442169847 and parameters: {'num_layers': 3, 'embed_size': 64, 'num_heads': 1, 'learning_rate': 0.003211687242714922, 'dropout_rate': 0.2}. Best is trial 24 with value: 0.1094187590337022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1476/0.1185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 02:29:46,510]\u001b[0m Trial 33 finished with value: 0.12158660121620268 and parameters: {'num_layers': 2, 'embed_size': 256, 'num_heads': 1, 'learning_rate': 0.005636754224807002, 'dropout_rate': 0.1}. Best is trial 24 with value: 0.1094187590337022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1669/0.1216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 02:39:05,663]\u001b[0m Trial 34 finished with value: 0.11615551223090041 and parameters: {'num_layers': 3, 'embed_size': 64, 'num_heads': 4, 'learning_rate': 0.0030679055227741006, 'dropout_rate': 0.30000000000000004}. Best is trial 24 with value: 0.1094187590337022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1688/0.1162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 02:58:01,119]\u001b[0m Trial 35 finished with value: 0.36824373559631607 and parameters: {'num_layers': 2, 'embed_size': 256, 'num_heads': 1, 'learning_rate': 0.0015340516763681375, 'dropout_rate': 0.4}. Best is trial 24 with value: 0.1094187590337022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.2229/0.3682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 03:02:42,011]\u001b[0m Trial 36 finished with value: 0.11028170894940661 and parameters: {'num_layers': 1, 'embed_size': 64, 'num_heads': 1, 'learning_rate': 0.0018668979083433024, 'dropout_rate': 0.5}. Best is trial 24 with value: 0.1094187590337022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1578/0.1103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 03:07:03,173]\u001b[0m Trial 37 finished with value: 0.13359464915632183 and parameters: {'num_layers': 1, 'embed_size': 16, 'num_heads': 2, 'learning_rate': 0.000969222677496624, 'dropout_rate': 0.5}. Best is trial 24 with value: 0.1094187590337022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1302/0.1336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 03:13:04,873]\u001b[0m Trial 38 finished with value: 0.126388345305206 and parameters: {'num_layers': 1, 'embed_size': 64, 'num_heads': 16, 'learning_rate': 0.001989178554812917, 'dropout_rate': 0.7000000000000001}. Best is trial 24 with value: 0.1094187590337022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1504/0.1264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 03:18:09,938]\u001b[0m Trial 39 finished with value: 0.12354080643578687 and parameters: {'num_layers': 1, 'embed_size': 32, 'num_heads': 8, 'learning_rate': 0.0022715655879794235, 'dropout_rate': 0.7000000000000001}. Best is trial 24 with value: 0.1094187590337022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1422/0.1235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 03:37:03,831]\u001b[0m Trial 40 finished with value: 0.1517943303320095 and parameters: {'num_layers': 2, 'embed_size': 256, 'num_heads': 2, 'learning_rate': 0.0063139099689688135, 'dropout_rate': 0.9}. Best is trial 24 with value: 0.1094187590337022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.6914/0.1518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 03:47:32,500]\u001b[0m Trial 41 finished with value: 0.11742753607372716 and parameters: {'num_layers': 4, 'embed_size': 64, 'num_heads': 1, 'learning_rate': 0.0035803434266178436, 'dropout_rate': 0.30000000000000004}. Best is trial 24 with value: 0.1094187590337022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1547/0.1174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 03:52:13,520]\u001b[0m Trial 42 finished with value: 0.13009047785444094 and parameters: {'num_layers': 1, 'embed_size': 64, 'num_heads': 1, 'learning_rate': 0.0015882368521835807, 'dropout_rate': 0.4}. Best is trial 24 with value: 0.1094187590337022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1634/0.1301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 03:58:48,472]\u001b[0m Trial 43 finished with value: 0.12759052657100653 and parameters: {'num_layers': 2, 'embed_size': 64, 'num_heads': 1, 'learning_rate': 0.002996041436642916, 'dropout_rate': 0.5}. Best is trial 24 with value: 0.1094187590337022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.16/0.1276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 04:07:19,096]\u001b[0m Trial 44 finished with value: 0.11692244373443253 and parameters: {'num_layers': 3, 'embed_size': 64, 'num_heads': 1, 'learning_rate': 3.978365286372158e-05, 'dropout_rate': 0.2}. Best is trial 24 with value: 0.1094187590337022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1405/0.1169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 04:13:01,933]\u001b[0m Trial 45 finished with value: 0.10868180113995528 and parameters: {'num_layers': 2, 'embed_size': 16, 'num_heads': 1, 'learning_rate': 0.007060943198960553, 'dropout_rate': 0.1}. Best is trial 45 with value: 0.10868180113995528.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1469/0.1087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 04:17:35,634]\u001b[0m Trial 46 finished with value: 0.3642611263273179 and parameters: {'num_layers': 1, 'embed_size': 16, 'num_heads': 4, 'learning_rate': 0.005229653738645501, 'dropout_rate': 0.0}. Best is trial 45 with value: 0.10868180113995528.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.368/0.3643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 04:23:44,574]\u001b[0m Trial 47 finished with value: 0.11438849946395752 and parameters: {'num_layers': 2, 'embed_size': 16, 'num_heads': 16, 'learning_rate': 0.008090579033206905, 'dropout_rate': 0.1}. Best is trial 45 with value: 0.10868180113995528.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1746/0.1144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 04:29:28,308]\u001b[0m Trial 48 finished with value: 0.11068478428064904 and parameters: {'num_layers': 2, 'embed_size': 16, 'num_heads': 1, 'learning_rate': 0.007102919499415657, 'dropout_rate': 0.4}. Best is trial 45 with value: 0.10868180113995528.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1373/0.1107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 04:33:50,074]\u001b[0m Trial 49 finished with value: 0.5524826129689304 and parameters: {'num_layers': 1, 'embed_size': 16, 'num_heads': 2, 'learning_rate': 0.009642851429880384, 'dropout_rate': 0.0}. Best is trial 45 with value: 0.10868180113995528.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.5238/0.5525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 04:38:18,366]\u001b[0m Trial 50 finished with value: 0.10858995755387868 and parameters: {'num_layers': 1, 'embed_size': 32, 'num_heads': 1, 'learning_rate': 5.449764952082217e-05, 'dropout_rate': 0.9}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1524/0.1086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 04:42:44,934]\u001b[0m Trial 51 finished with value: 0.11210912751284301 and parameters: {'num_layers': 1, 'embed_size': 32, 'num_heads': 1, 'learning_rate': 2.2440465387479034e-05, 'dropout_rate': 0.9}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1571/0.1121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 04:47:12,274]\u001b[0m Trial 52 finished with value: 0.1123534305670987 and parameters: {'num_layers': 1, 'embed_size': 32, 'num_heads': 1, 'learning_rate': 1.7392782060711776e-05, 'dropout_rate': 0.8}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1583/0.1124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 04:51:38,673]\u001b[0m Trial 53 finished with value: 0.16469822835794837 and parameters: {'num_layers': 1, 'embed_size': 32, 'num_heads': 1, 'learning_rate': 4.226241998393557e-05, 'dropout_rate': 1.0}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.2267/0.1647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 04:57:42,695]\u001b[0m Trial 54 finished with value: 0.11425364966266191 and parameters: {'num_layers': 2, 'embed_size': 32, 'num_heads': 1, 'learning_rate': 0.004417967219890875, 'dropout_rate': 0.9}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1585/0.1143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 05:03:24,544]\u001b[0m Trial 55 finished with value: 0.1158705764362364 and parameters: {'num_layers': 1, 'embed_size': 32, 'num_heads': 16, 'learning_rate': 0.00022403838714904893, 'dropout_rate': 0.8}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1548/0.1159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 05:10:18,023]\u001b[0m Trial 56 finished with value: 0.11384886587399251 and parameters: {'num_layers': 2, 'embed_size': 16, 'num_heads': 8, 'learning_rate': 6.910409249923243e-05, 'dropout_rate': 0.6000000000000001}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1575/0.1138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 05:16:51,026]\u001b[0m Trial 57 finished with value: 0.1125818627469424 and parameters: {'num_layers': 1, 'embed_size': 128, 'num_heads': 1, 'learning_rate': 0.002473213518255137, 'dropout_rate': 0.1}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1391/0.1126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 05:22:56,847]\u001b[0m Trial 58 finished with value: 0.11006240766778992 and parameters: {'num_layers': 2, 'embed_size': 32, 'num_heads': 1, 'learning_rate': 0.007594797606640733, 'dropout_rate': 0.7000000000000001}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1448/0.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 05:35:34,829]\u001b[0m Trial 59 finished with value: 0.1206435299046346 and parameters: {'num_layers': 6, 'embed_size': 32, 'num_heads': 1, 'learning_rate': 0.007004484118412864, 'dropout_rate': 0.9}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1592/0.1206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 05:47:09,467]\u001b[0m Trial 60 finished with value: 0.11252234708410555 and parameters: {'num_layers': 3, 'embed_size': 32, 'num_heads': 16, 'learning_rate': 0.004690699426447086, 'dropout_rate': 0.8}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1471/0.1125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 05:53:16,703]\u001b[0m Trial 61 finished with value: 0.11437069382470177 and parameters: {'num_layers': 2, 'embed_size': 32, 'num_heads': 1, 'learning_rate': 0.008044350823356293, 'dropout_rate': 0.7000000000000001}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1388/0.1144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 05:59:22,935]\u001b[0m Trial 62 finished with value: 0.11730197319179439 and parameters: {'num_layers': 2, 'embed_size': 32, 'num_heads': 1, 'learning_rate': 0.005430127014851284, 'dropout_rate': 1.0}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1527/0.1173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 06:05:56,494]\u001b[0m Trial 63 finished with value: 0.34018444818458593 and parameters: {'num_layers': 1, 'embed_size': 128, 'num_heads': 1, 'learning_rate': 0.004064125399476699, 'dropout_rate': 0.7000000000000001}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1728/0.3402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 06:12:02,579]\u001b[0m Trial 64 finished with value: 0.11554085468046668 and parameters: {'num_layers': 2, 'embed_size': 32, 'num_heads': 1, 'learning_rate': 0.0068185091832433, 'dropout_rate': 0.6000000000000001}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1393/0.1155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 06:19:09,743]\u001b[0m Trial 65 finished with value: 0.4918457160839895 and parameters: {'num_layers': 2, 'embed_size': 64, 'num_heads': 4, 'learning_rate': 0.009725900248579332, 'dropout_rate': 0.8}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.264/0.4918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 06:29:58,690]\u001b[0m Trial 66 finished with value: 0.11940125358833029 and parameters: {'num_layers': 1, 'embed_size': 256, 'num_heads': 1, 'learning_rate': 0.0007233722593442728, 'dropout_rate': 0.30000000000000004}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1428/0.1194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 06:37:08,231]\u001b[0m Trial 67 finished with value: 0.11414305842032661 and parameters: {'num_layers': 3, 'embed_size': 16, 'num_heads': 1, 'learning_rate': 1.2631828604328644e-05, 'dropout_rate': 0.9}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1519/0.1141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 06:49:52,287]\u001b[0m Trial 68 finished with value: 0.11913336232400408 and parameters: {'num_layers': 4, 'embed_size': 64, 'num_heads': 8, 'learning_rate': 0.0032598478055964352, 'dropout_rate': 0.5}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1563/0.1191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 06:55:35,584]\u001b[0m Trial 69 finished with value: 0.11799748357631855 and parameters: {'num_layers': 1, 'embed_size': 32, 'num_heads': 16, 'learning_rate': 0.0061325477018659225, 'dropout_rate': 0.2}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1313/0.118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 07:02:10,041]\u001b[0m Trial 70 finished with value: 0.33717991011181486 and parameters: {'num_layers': 2, 'embed_size': 64, 'num_heads': 1, 'learning_rate': 0.0011595706945507886, 'dropout_rate': 0.0}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.4425/0.3372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 07:07:52,419]\u001b[0m Trial 71 finished with value: 0.11286631782546133 and parameters: {'num_layers': 2, 'embed_size': 16, 'num_heads': 1, 'learning_rate': 0.007552880605588781, 'dropout_rate': 0.5}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1464/0.1129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 07:13:35,746]\u001b[0m Trial 72 finished with value: 0.11166580990995058 and parameters: {'num_layers': 2, 'embed_size': 16, 'num_heads': 1, 'learning_rate': 0.005310169356447677, 'dropout_rate': 0.4}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1314/0.1117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 07:19:18,805]\u001b[0m Trial 73 finished with value: 0.11297552349375348 and parameters: {'num_layers': 2, 'embed_size': 16, 'num_heads': 1, 'learning_rate': 0.007960147583328464, 'dropout_rate': 0.4}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1446/0.113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 07:26:27,899]\u001b[0m Trial 74 finished with value: 0.11288443163844133 and parameters: {'num_layers': 3, 'embed_size': 16, 'num_heads': 1, 'learning_rate': 0.0027004927063622054, 'dropout_rate': 0.4}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1419/0.1129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-20 07:30:48,107]\u001b[0m Trial 75 finished with value: 0.11558264762697425 and parameters: {'num_layers': 1, 'embed_size': 16, 'num_heads': 2, 'learning_rate': 0.0034709391996154398, 'dropout_rate': 0.5}. Best is trial 50 with value: 0.10858995755387868.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train/Valid Loss: 0.1667/0.1156\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Integer parameter\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 6)\n",
    "\n",
    "    # Integer parameter (log)\n",
    "    embed_size = trial.suggest_categorical(\"embed_size\", [2**i for i in range(4,9)])\n",
    "\n",
    "    # Integer parameter (discretized)\n",
    "    num_heads = trial.suggest_categorical(\"num_heads\", [2**i for i in range(0,5)])\n",
    "\n",
    "\n",
    "    # Floating point parameter (log)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "\n",
    "    # Floating point parameter (discretized)\n",
    "    drop_path_rate = trial.suggest_float(\"dropout_rate\", 0.0, 1.0, step=0.1)\n",
    "    \n",
    "    search_model = TFModelLite(task_dim=n_dims + n_objs + n_tasks, traj_dim=n_dims, \n",
    "                            embed_dim=embed_size, nhead=num_heads, layers=num_layers,\n",
    "                              dropout=drop_path_rate).to(device)\n",
    "    search_opt = optim.Adam(search_model.parameters(), lr=drop_path_rate)\n",
    "    for i in range(1000):\n",
    "        t_losses  = train_epoch(search_model, search_opt, train_dataloader)\n",
    "  \n",
    "    search_model.eval()\n",
    "    v_losses = []\n",
    "    for sample_batched in valid_dataloader:\n",
    "        obj_seq, traj_seq, traj_target = sample_batched\n",
    "        obj_seq_input = obj_seq.to(device)\n",
    "        traj_seq_gt = traj_seq.to(device)\n",
    "        traj_target_input = traj_target.to(device)\n",
    "        output_seq = search_model(obj_seq_input, traj_target_input)\n",
    "        loss = F.mse_loss(output_seq, traj_seq_gt[:,:,:n_dims])\n",
    "        v_losses.append(loss.item())\n",
    "    t_loss_mean, v_loss_mean = mean(t_losses), mean(v_losses)\n",
    "    print(f\"Epoch {epoch}, Train/Valid Loss: {round(t_loss_mean,4)}/{round(v_loss_mean,4)}\")\n",
    "    del search_model\n",
    "    return v_loss_mean\n",
    "    \n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_file = os.path.join(model_path, \"saved_study.pkl\")\n",
    "with open(study_file, \"wb\") as fout:\n",
    "    pickle.dump(study, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while epoch < total_epochs:\n",
    "    start = time.time()\n",
    "    t_losses = train_epoch(new_model, adam, train_dataloader)\n",
    "    if epoch%print_interval==0:\n",
    "        new_model.eval()\n",
    "        v_losses = []\n",
    "        for sample_batched in valid_dataloader:\n",
    "            obj_seq, traj_seq, traj_target = sample_batched\n",
    "            obj_seq_input = obj_seq.to(device)\n",
    "            traj_seq_gt = traj_seq.to(device)\n",
    "            traj_target_input = traj_target.to(device)\n",
    "            output_seq = new_model(obj_seq_input, traj_target_input)\n",
    "            loss = F.mse_loss(output_seq, traj_seq_gt[:,:,:n_dims])\n",
    "            v_losses.append(loss.item())\n",
    "        t_loss_mean, v_loss_mean = mean(t_losses), mean(v_losses)\n",
    "        print(f\"Epoch {epoch}, Train/Valid Loss: {round(t_loss_mean,4)}/{round(v_loss_mean,4)}\",\n",
    "             f\"Runtime: {round(time.time()-start, 2)}s\")\n",
    "        loss_hist.append([t_loss_mean, v_loss_mean])\n",
    "        if best_score > v_loss_mean:\n",
    "            best_score = v_loss_mean\n",
    "            best_epoch = epoch\n",
    "            best_file = os.path.join(model_path, f\"best2_{n_dims}D_{n_train}dms.pt\")\n",
    "            best_checkpoint = { \n",
    "                'epoch': epoch,\n",
    "                'best_epoch': best_epoch,\n",
    "                'losses':loss_hist,\n",
    "                'model': new_model,\n",
    "                'optimizer': adam}\n",
    "            torch.save(best_checkpoint, best_file)\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# torch.save(new_model, model_file)\n",
    "# with open(filepath, 'wb') as handle:\n",
    "#     pickle.dump(loss_hist, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_obj_index(onehot):\n",
    "    for i in range(onehot.shape[0]):\n",
    "        if onehot[i]==1:\n",
    "            return i\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = { \n",
    "#     'epoch': epoch,\n",
    "#     'best_epoch': best_epoch,\n",
    "#     'losses':loss_hist,\n",
    "#     'model': new_model,\n",
    "#     'optimizer': adam}\n",
    "# torch.save(checkpoint, checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.eval()\n",
    "plot_dataloader = DataLoader(test_data, batch_size=1)\n",
    "tfile = task_files[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "demo_input = next(iter(plot_dataloader))\n",
    "obj_seq, traj_seq, traj_target = demo_input\n",
    "# if to_obj_index(task_tags[tfile])!=to_obj_index(obj_seq[0,0,-n_tasks:]): \n",
    "#     print(obj_seq[0,0,-n_tasks:])\n",
    "obj_seq_input = obj_seq.to(device)\n",
    "traj_target_input = traj_target.to(device)\n",
    "\n",
    "predicted_traj_tf = new_model(obj_seq_input, traj_target_input).cpu()\n",
    "predicted_traj = predicted_traj_tf.detach().numpy()\n",
    "mask = traj_seq[0,:,n_dims]==1\n",
    "d = get_position_difference_per_step(predicted_traj[0,mask,:3], traj_seq.numpy()[0,mask,:3])*train_std\n",
    "print(f\"Transformer Model({n_dims}D) average distance: {np.mean(d)}mm\\nStart distance {d[0]}mm, End distance: {d[-1]}mm\")\n",
    "matplotlib.rcParams.update({'font.size': 10})\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "ax2 = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "colors = ['red', 'blue', 'yellow', 'orange', 'green', 'purple','pink']\n",
    "obj0_pos = obj_seq[0,0,]*train_std\n",
    "obj1_pos = obj_seq[0,1,]*train_std\n",
    "traj_seq.squeeze(0)\n",
    "mask = traj_seq[0,:,n_dims]==1\n",
    "scaled_traj_seq = traj_seq[0,mask]*train_std\n",
    "scaled_predicted_traj = predicted_traj[0,mask]*train_std\n",
    "line = ax2.plot(scaled_traj_seq[:,2], scaled_traj_seq[:,1], -scaled_traj_seq[:,0],\n",
    "                 '--', color='red', label = f'ground truth')\n",
    "ax2.plot(obj0_pos[2], obj0_pos[1], -obj0_pos[0], 'o',\n",
    "        color='red', label=f'{unique_objs[to_obj_index(obj0_pos[n_dims:n_dims+n_objs])]}')\n",
    "ax2.plot(obj1_pos[2], obj1_pos[1], -obj1_pos[0], 'x',\n",
    "        color='red', label=f'{unique_objs[to_obj_index(obj1_pos[n_dims:n_dims+n_objs])]}')\n",
    "line = ax2.plot(scaled_predicted_traj[:,2], scaled_predicted_traj[:,1], -scaled_predicted_traj[:,0], '--', color='blue', \n",
    "               label = f'predicted')\n",
    "\n",
    "ax2.set_xlabel('x (mm)')\n",
    "ax2.set_ylabel('y (mm)')\n",
    "ax2.set_zlabel('z (mm)')\n",
    "ax2.set_box_aspect([ub - lb for lb, ub in (getattr(ax2, f'get_{a}lim')() for a in 'xyz')])\n",
    "\n",
    "plt.legend(loc = 'upper left',  prop={'size': 10})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib.rcParams.update({'font.size': 10})\n",
    "# fig = plt.figure(figsize = (9, 2*n_dims))\n",
    "# axs = fig.subplots(n_dims, 1)\n",
    "\n",
    "# for i in range(n_dims):\n",
    "#     axs[i].plot(-traj_seq[0,mask,i], color='red',  label = f' ground truth')\n",
    "#     axs[i].plot(-predicted_traj[mask,i], color='blue', label=f'predict')\n",
    "#     axs[i].set_xlabel('time')\n",
    "#     axs[i].set_ylabel(task_dims[i])\n",
    "#     axs[i].set_title(f'{task_dims[i]}-axis vs Time')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "F.mse_loss(predicted_traj_tf, traj_seq[:,:,:n_dims])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = []\n",
    "task_names = [\"Pick&Place\", \"Pouring\", \"Pucking\"]\n",
    "for i, file in enumerate(task_files):\n",
    "    for demo_input in plot_dataloader:\n",
    "        obj_seq, traj_seq, traj_target = demo_input\n",
    "        if to_obj_index(task_tags[file])!=to_obj_index(obj_seq[0,0,-n_tasks:]): continue\n",
    "        obj_seq_input = obj_seq.to(device)\n",
    "        traj_target_input = traj_target.to(device)\n",
    "        predicted_traj_tf = new_model(obj_seq_input, traj_target_input).cpu()\n",
    "        predicted_traj = predicted_traj_tf.detach().numpy()[0]\n",
    "        mask = traj_seq[0,:,n_dims]==1\n",
    "        d = get_position_difference_per_step(predicted_traj[mask,:3], traj_seq.numpy()[0,mask,:3])*train_std\n",
    "        distances.append([d[0], d[-1], np.mean(d)])\n",
    "    mean_ds = np.mean(np.array(distances), axis = 0)\n",
    "    print(f\"{task_names[i]}({n_dims}D) -- Average distance: {mean_ds[-1]}mm\\nStart: {mean_ds[0]}mm, End: {mean_ds[1]}mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pick&Place(7D) -- Average distance: 62.9868538975021mm\n",
    "Start: 42.26923237081197mm, End: 79.4552935564277mm\n",
    "Pouring(7D) -- Average distance: 58.23420816977872mm\n",
    "Start: 37.770702922837636mm, End: 101.59201766144635mm\n",
    "Pucking(7D) -- Average distance: 55.91966660978153mm\n",
    "Start: 36.81040472164073mm, End: 84.82568633828863mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pick&Place(7D) -- Average distance: 36.98310315657745mm\n",
    "Start: 21.2115110550846mm, End: 47.86264182557085mm\n",
    "Pouring(7D) -- Average distance: 46.367497285512215mm\n",
    "Start: 24.491665857492908mm, End: 87.40841715349492mm\n",
    "Pucking(7D) -- Average distance: 47.31723368561045mm\n",
    "Start: 27.708466152663124mm, End: 75.37036924421082mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pick&Place(7D) -- Average distance: 29.20051638363695mm\n",
    "Start: 12.295744638832234mm, End: 34.171612610837954mm\n",
    "Pouring(7D) -- Average distance: 39.874439044829494mm\n",
    "Start: 16.50106556405996mm, End: 72.80145115882218mm\n",
    "Pucking(7D) -- Average distance: 42.77711302522513mm\n",
    "Start: 20.29008394561259mm, End: 64.28164246493601mm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
